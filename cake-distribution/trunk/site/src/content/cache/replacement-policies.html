<html>
<!--
 Copyright 2008, 2009 Kasper Nielsen
   Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
 
 Created on 5. March 2009 by Kasper Nielsen
 -->
  <head>
    <title>Replacement Policies</title>
    <meta name="short" content="Replacement Policies"/>
  </head>
  <body>
    <p>
In many use cases the amount of data is greater then the available amount of memory. 
When a cache is full and a new element is added. The cache must evict one of the existing elements 
in order to make room for the new element. The algorithm that determines which entry that 
should be evicted is called a cache replacement policy (or sometimes just a replacement policy).
  </p>
   <p>
A naive replacement policy might just select a random element to evict. 
However, a common observation for most workloads is that elements that have been accessed recently have a 
tendency to be accessed again in the near future. This concept is known as <i>temporal locality</i>. 
This is probably best embodied in the Least Recently Used (LRU) replacement policy which is 
commonly used in many computer systems. While LRU works great for many workloads the 
naive randomized implementation work better for other workloads, for example, if a cache is all entries are 
continuously accessed in a circular pattern.
    </p>


    <h1>Paging based replacement policies</h1>
   <p>
    A replacement policy based on paging is a policy where all elements have uniform sizes and cost to retrieve. 
    That is a document with a size of 1 MB and one with a size of 10 MB is treated equally by the policy both in respect to 
    memory usage and cost to retrieve.

    The best, offline cache replacement policy is Belady's MIN that replaces the page that is used farthest in the future[1]. 
    Of course, in practice, we are only interested in online cache replacement policies that do not demand any prior knowledge of the workload.
</p>    
    <h1>Cost/Size based replacement policies</h1>
    <p>
    Consider a small application that consists of 10 documents that the users access randomly. 
    9 of the documents needs 1 MB to be stored while the last document needs 5 MB to be stored.
	If we only have 10 MB available to store documents, we can either choose     
    </p>
  </body>
</html>
